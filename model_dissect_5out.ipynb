{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "# %% \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "#%%\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def grad_loss(v_gt, v):\n",
    "    # Gradient loss\n",
    "    loss = tf.reduce_mean(tf.abs(v - v_gt), axis=[1,2,3])\n",
    "    jy = v[:,:,1:,:,:] - v[:,:,:-1,:,:]\n",
    "    jx = v[:,:,:,1:,:] - v[:,:,:,:-1,:]\n",
    "    jy_ = v_gt[:,:,1:,:,:] - v_gt[:,:,:-1,:,:]\n",
    "    jx_ = v_gt[:,:,:,1:,:] - v_gt[:,:,:,:-1,:]\n",
    "    loss += tf.reduce_mean(tf.abs(jy - jy_), axis=[1,2,3])\n",
    "    loss += tf.reduce_mean(tf.abs(jx - jx_), axis=[1,2,3])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uNet(input, time, lat, lon, height, kernel = [5, 3, 3], nodes = [72, 144, 288, 576]):\n",
    "    '''\n",
    "    This function defines a U-Net architecture\n",
    "    :param input: the main-input layer\n",
    "    :param time: the time input layer\n",
    "    :param lat, lon, height: additional fields\n",
    "    :param kernel: Kernel-sizes (default = [5, 3, 3])\n",
    "    :param nodes: different neuron-sizes if needed (default = [72, 144, 288, 576])\n",
    "    :return: last layer of constructed model\n",
    "    '''\n",
    "\n",
    "    # set Timesteps\n",
    "    TS = 3\n",
    "    ##################################################### 1st Block ####################################################\n",
    "    conv1 = Conv3D(filters      = nodes[0],\n",
    "                   kernel_size  = (TS, kernel[0], kernel[0]),\n",
    "                   activation   = 'relu',\n",
    "                   padding      = 'same',\n",
    "                   data_format  = 'channels_last')(input)\n",
    "    mergetime = Concatenate(axis=4)([conv1, lat, lon, height])\n",
    "    conv1 = Conv3D(filters      = nodes[0],\n",
    "                   kernel_size  = kernel[0],\n",
    "                   activation   = 'relu',\n",
    "                   padding      = 'same',\n",
    "                   data_format  = 'channels_last')(mergetime)\n",
    "\n",
    "    pool1 = MaxPooling3D(pool_size = (1, 2, 2))(conv1)\n",
    "\n",
    "    ##################################################### 2nd Block ####################################################\n",
    "    conv2 = Conv3D(filters      = nodes[1],\n",
    "                   kernel_size  = (TS, kernel[1], kernel[1]),\n",
    "                   activation   = 'relu',\n",
    "                   padding      = 'same',\n",
    "                   data_format  = 'channels_last')(pool1)\n",
    "    conv2 = Conv3D(filters      = nodes[1],\n",
    "                   kernel_size  = (TS, kernel[1], kernel[1]),\n",
    "                   activation   = 'relu',\n",
    "                   padding      = 'same',\n",
    "                   data_format  = 'channels_last')(conv2)\n",
    "\n",
    "    pool2 = MaxPooling3D(pool_size = (1, 2, 2))(conv2)\n",
    "\n",
    "    ##################################################### 3rd Block ####################################################\n",
    "    conv3 = Conv3D(filters      = nodes[2],\n",
    "                   kernel_size  = (TS, kernel[2], kernel[2]),\n",
    "                   activation = 'relu',\n",
    "                   padding      = 'same',\n",
    "                   data_format  = 'channels_last')(pool2)\n",
    "    conv3 = Conv3D(filters      = nodes[2],\n",
    "                   kernel_size  = (TS, kernel[2], kernel[2]),\n",
    "                   activation='relu',\n",
    "                   padding      = 'same',\n",
    "                   data_format  = 'channels_last')(conv3)\n",
    "\n",
    "    pool3 = MaxPooling3D(pool_size = (1, 2, 2))(conv3)\n",
    "\n",
    "    ##################################################### 4th Block ####################################################\n",
    "    conv4 = Conv3D(filters      = nodes[3],\n",
    "                   kernel_size  = (TS, kernel[2], kernel[2]),\n",
    "                   activation='relu',\n",
    "                   padding      = 'same',\n",
    "                   data_format  = 'channels_last')(pool3)\n",
    "    conv4 = Conv3D(filters      = nodes[3],\n",
    "                   kernel_size  = (TS, kernel[2], kernel[2]),\n",
    "                   activation='relu',\n",
    "                   padding      = 'same',\n",
    "                   data_format  = 'channels_last')(conv4)\n",
    "\n",
    "    ####################################################### TIME #######################################################\n",
    "    # Merge time-layer at this point\n",
    "    mergetime = Concatenate(axis=4)([conv4, time])\n",
    "\n",
    "    ################################################### UP 3rd Block ###################################################\n",
    "    # Up-Size again\n",
    "    up3   = UpSampling3D(size = (1, 2, 2))(mergetime)\n",
    "    up3   = Conv3D(filters              = nodes[2],\n",
    "                   kernel_size          = (TS, kernel[1], kernel[1]),\n",
    "                   activation           = 'relu',\n",
    "                   padding              = 'same',\n",
    "                   kernel_initializer   = 'he_normal')(up3)\n",
    "\n",
    "    # Skip connection\n",
    "    merge3 = Concatenate(axis=4)([conv3, up3])\n",
    "\n",
    "    conv3 = Conv3D(filters              = nodes[2],\n",
    "                   kernel_size          = (TS, kernel[1], kernel[1]),\n",
    "                   activation           = 'relu',\n",
    "                   padding              = 'same',\n",
    "                   data_format          = 'channels_last')(merge3)\n",
    "    conv3 = Conv3D(filters              = nodes[2],\n",
    "                   kernel_size          = (TS, kernel[1], kernel[1]),\n",
    "                   activation           = 'relu',\n",
    "                   padding              = 'same',\n",
    "                   data_format          = 'channels_last')(conv3)\n",
    "\n",
    "    ################################################### UP 2nd Block ###################################################\n",
    "    up2 = UpSampling3D(size = (1, 2, 2))(conv3)\n",
    "    up2 = Conv3D(filters                = nodes[1],\n",
    "                 kernel_size            = (TS, kernel[1], kernel[1]),\n",
    "                 activation             = 'relu',\n",
    "                 padding                = 'same',\n",
    "                 kernel_initializer     = 'he_normal')(up2)\n",
    "\n",
    "    # Skip connection\n",
    "    merge2 = Concatenate(axis=4)([conv2, up2])\n",
    "\n",
    "    conv2 = Conv3D(filters              = nodes[1],\n",
    "                   kernel_size          = (TS, kernel[1], kernel[1]),\n",
    "                   activation           = 'relu',\n",
    "                   padding              = 'same',\n",
    "                   data_format          = 'channels_last')(merge2)\n",
    "    conv2 = Conv3D(filters              = nodes[1],\n",
    "                   kernel_size          = (TS, kernel[1], kernel[1]),\n",
    "                   activation           = 'relu',\n",
    "                   padding              = 'same',\n",
    "                   data_format          = 'channels_last')(conv2)\n",
    "\n",
    "    ################################################### UP 1st Block ###################################################\n",
    "    up1 = UpSampling3D(size = (1, 2, 2))(conv2)\n",
    "    up1 = Conv3D(filters                = nodes[0],\n",
    "                 kernel_size            = (TS, kernel[0], kernel[0]),\n",
    "                 activation             = 'relu',\n",
    "                 padding                = 'same',\n",
    "                 kernel_initializer     = 'he_normal')(up1)\n",
    "\n",
    "    merge1 = Concatenate(axis=4)([conv1, up1])\n",
    "\n",
    "    conv1 = Conv3D(filters              = nodes[0],\n",
    "                   kernel_size          = (TS, kernel[0], kernel[0]),\n",
    "                   activation           = 'relu',\n",
    "                   padding              = 'same',\n",
    "                   data_format          = 'channels_last')(merge1)\n",
    "    conv1 = Conv3D(filters              = nodes[0],\n",
    "                   kernel_size          = (TS, kernel[0], kernel[0]),\n",
    "                   activation           = 'relu',\n",
    "                   padding              = 'same',\n",
    "                   data_format          = 'channels_last')(conv1)\n",
    "\n",
    "    # last layer is the output\n",
    "    output = conv1\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(PS=32, loss = grad_loss, optimizer = 'adam', nodes = [72, 144, 288, 576], residual = False):\n",
    "    '''\n",
    "    This function creates the DCN-architecture (residual = False) or RPN-architecture (residual = True).\n",
    "    :param PS: Patch size\n",
    "    :param loss: loss function (default = grad_loss)\n",
    "    :param optimizer: optimizer (default = 'adam')\n",
    "    :param nodes: different neuron-sizes if needed (default = [72, 144, 288, 576])\n",
    "    :param residual: boolean toggeling between RPN (True) and DCN (False)\n",
    "    :return: Model\n",
    "    '''\n",
    "\n",
    "    # Input layers\n",
    "    main_input  = Input(shape = (3, PS, PS, 1)) # (PS, PS, 3), filters = 5\n",
    "    time        = Input(shape = (3, int(PS/8), int(PS/8), 1))\n",
    "    lat         = Input(shape = (3, PS, PS, 1))\n",
    "    lon         = Input(shape = (3, PS, PS, 1)) \n",
    "    height      = Input(shape = (3, PS, PS, 1))\n",
    "\n",
    "    # Load U-Net\n",
    "    unet        = uNet(main_input, time, lat, lon, height, nodes = nodes)\n",
    "\n",
    "    # Define output layer after U-Net\n",
    "    temp_out    = Conv3D(filters        = 1,\n",
    "                         kernel_size    = (3, 1, 1),\n",
    "                         activation     = 'linear',\n",
    "                         padding        = 'same',\n",
    "                         data_format    = \"channels_last\")(unet)\n",
    "\n",
    "    def transpose_fn(x):\n",
    "      return tf.transpose(x, perm=[0, 4, 2, 3, 1])\n",
    "    temp_out = Lambda(transpose_fn)(temp_out)\n",
    "    # # Define output layer after U-Net\n",
    "    temp_out    = Conv3D(filters        = 5,\n",
    "                         kernel_size    = (1, 1, 1),\n",
    "                         activation     = 'linear',\n",
    "                         padding        = 'valid',\n",
    "                         data_format    = \"channels_last\")(temp_out)\n",
    "    temp_out = Lambda(transpose_fn)(temp_out)\n",
    "    \n",
    "    # residual layer\n",
    "    if residual:\n",
    "        temp_out = Add()([main_input[:,1,:,:], temp_out])\n",
    "\n",
    "    # create model with the defined Layers\n",
    "    model       = Model(inputs          = [main_input, time, lat, lon, height],\n",
    "                        outputs         = temp_out)\n",
    "\n",
    "    # compile with defined loss and optimizer\n",
    "    model.compile(loss      = loss,\n",
    "                  optimizer = optimizer,\n",
    "                  metrics   = ['mse', 'mae', 'mape'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def main():\n",
    "  model = get_model() # DCN\n",
    "#   model = get_model(residual=True) # RPN\n",
    "  model.summary()\n",
    "  print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want data in the size of patch_size x patch_size in time step of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52704, 23, 34, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "wind_speed_data = np.load('tensor.npy')  # Assuming wind speed is in the first channel\n",
    "print(wind_speed_data.shape)\n",
    "wind_speed_data = wind_speed_data[:, :, :, 0]  # Extract wind speed channel\n",
    "\n",
    "# Normalize the data\n",
    "wind_speed_data = (wind_speed_data - np.min(wind_speed_data)) / (np.max(wind_speed_data) - np.min(wind_speed_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52704, 23, 34)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wind_speed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52702, 3, 32, 32, 1)\n",
      "(52702, 3, 4, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Reshape data to fit the model input shape\n",
    "def reshape_data(data, patch_size=32, time_steps=3):\n",
    "    # Define the target shape\n",
    "    target_shape = (32, 32)\n",
    "    data = data[..., np.newaxis]\n",
    "    # Use tf.image.resize to resize the images\n",
    "    resized_data = tf.image.resize(data, target_shape, method='bilinear')\n",
    "\n",
    "    # Convert back to NumPy array if needed\n",
    "    data = resized_data.numpy()\n",
    "\n",
    "\n",
    "    num_samples = data.shape[0] - time_steps + 1\n",
    "    patches = []\n",
    "    time_patches = []\n",
    "    relative_time = np.zeros((3, 4, 4, 1))\n",
    "\n",
    "    # Assign specific values to each slice along the first axis\n",
    "    relative_time[0, :, :, 0] = -1\n",
    "    relative_time[1, :, :, 0] = 0\n",
    "    relative_time[2, :, :, 0] = 1\n",
    "    for i in range(num_samples):\n",
    "        # print(i, i +time_steps)\n",
    "        patch = data[i:i+time_steps, :, :32]\n",
    "        patches.append(patch)\n",
    "        time_patches.append(relative_time)\n",
    "    patches = np.array(patches)\n",
    "    time_patches = np.array(time_patches)\n",
    "    print(patches.shape)\n",
    "    print(time_patches.shape)\n",
    "    # patches = np.expand_dims(patches, axis=-1)  # Add channel dimension\n",
    "    return patches, time_patches\n",
    "\n",
    "# Example reshape\n",
    "patch_size = 32\n",
    "time_steps = 3\n",
    "wind_speed_patches, time_patches = reshape_data(wind_speed_data, patch_size, time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input patches shape: (52700, 3, 32, 32, 1)\n",
      "Input time patches shape: (52700, 3, 4, 4, 1)\n",
      "Label patches shape: (52700, 5, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Reshape data to fit the model input shape\n",
    "def reshape_data(data, target_shape=(32, 32)):\n",
    "    # Reshape data to the target shape\n",
    "    data = data[..., np.newaxis]\n",
    "    resized_data = tf.image.resize(data, target_shape, method='bilinear')\n",
    "    data = resized_data.numpy()\n",
    "    return data\n",
    "\n",
    "def create_patches(data, time_steps):\n",
    "    num_samples = data.shape[0] - time_steps + 1\n",
    "    training_patches = []\n",
    "    patches = []\n",
    "\n",
    "    \n",
    "\n",
    "    for i in range(num_samples):\n",
    "        patch = data[i:i+time_steps]\n",
    "        patches.append(patch)\n",
    "        training_patches.append(patch[::2])\n",
    "    training_timestep = time_steps//2+1\n",
    "    relative_time = np.zeros((time_steps//2+1, data.shape[1]//8, data.shape[2]//8, 1))\n",
    "    # relative_time = np.zeros((3, 4, 4, 1))\n",
    "\n",
    "    # Assign specific values to each slice along the first axis\n",
    "    # relative_time[0, :, :, 0] = -1\n",
    "    # relative_time[1, :, :, 0] = 0\n",
    "    # relative_time[2, :, :, 0] = 1\n",
    "    for t in range(training_timestep):\n",
    "        relative_time[t, :, :, 0] = t\n",
    "    relative_time_patches = np.tile(relative_time, (num_samples, 1, 1, 1, 1))\n",
    "    training_patches = np.array(training_patches)\n",
    "    patches = np.array(patches)\n",
    "\n",
    "    return training_patches, relative_time_patches, patches\n",
    "\n",
    "\n",
    "# Parameters\n",
    "patch_size = 32\n",
    "time_steps_label = 5\n",
    "\n",
    "# Reshape data\n",
    "reshaped_data = reshape_data(wind_speed_data, target_shape=(32, 32))\n",
    "\n",
    "# Create label patches with time_steps_label\n",
    "input_patches, input_time_patches, label_patches = create_patches(reshaped_data, time_steps_label)\n",
    "\n",
    "# input_patches, input_time_patches = input_patches[:label_patches.shape[0],:,:,:,:], input_time_patches[:label_patches.shape[0],:,:,:,:]\n",
    "\n",
    "print(\"Input patches shape:\", input_patches.shape)\n",
    "print(\"Input time patches shape:\", input_time_patches.shape)\n",
    "print(\"Label patches shape:\", label_patches.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split data\n",
    "# train_inputs, val_inputs, train_inputs_time, val_inputs_time = train_test_split(\n",
    "#     input_patches, input_time_patches, test_size=0.2, random_state=42)\n",
    "\n",
    "# train_labels, val_labels, train_labels_time, val_labels_time = train_test_split(\n",
    "#     label_patches, test_size=0.2, random_state=42)\n",
    "# print(\"Training input patches shape:\", train_inputs.shape)\n",
    "# print(\"Training input time patches shape:\", train_inputs_time.shape)\n",
    "# print(\"Val input time patches shape:\", val_inputs_time.shape)\n",
    "# print(\"Validation input patches shape:\", val_inputs.shape)\n",
    "# print(\"Training label patches shape:\", train_labels.shape)\n",
    "# print(\"Validation label patches shape:\", val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the size of the training set\n",
    "train_size = int(0.001 * len(input_patches))  # 80% for training\n",
    "\n",
    "# Create indices\n",
    "indices = np.arange(len(input_patches))\n",
    "np.random.seed(42)  # Set seed for reproducibility\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Split indices into training and validation\n",
    "train_indices = indices[:train_size]\n",
    "val_indices = indices[train_size:]\n",
    "\n",
    "# Use the indices to split the data\n",
    "train_inputs = input_patches[train_indices]\n",
    "val_inputs = input_patches[val_indices]\n",
    "\n",
    "train_inputs_time = input_time_patches[train_indices]\n",
    "val_inputs_time = input_time_patches[val_indices]\n",
    "\n",
    "train_labels = label_patches[train_indices]\n",
    "val_labels = label_patches[val_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training input patches shape: (52, 3, 32, 32, 1)\n",
      "Training input time patches shape: (52, 3, 4, 4, 1)\n",
      "Val input time patches shape: (52648, 3, 4, 4, 1)\n",
      "Validation input patches shape: (52648, 3, 32, 32, 1)\n",
      "Training label patches shape: (52, 5, 32, 32, 1)\n",
      "Validation label patches shape: (52648, 5, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training input patches shape:\", train_inputs.shape)\n",
    "print(\"Training input time patches shape:\", train_inputs_time.shape)\n",
    "print(\"Val input time patches shape:\", val_inputs_time.shape)\n",
    "print(\"Validation input patches shape:\", val_inputs.shape)\n",
    "print(\"Training label patches shape:\", train_labels.shape)\n",
    "print(\"Validation label patches shape:\", val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_inputs = val_inputs[:10,:,:,:,:]\n",
    "\n",
    "val_inputs_time = val_inputs_time[:10,:,:,:,:]\n",
    "\n",
    "val_labels = val_labels[:10,:,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 5, 32, 32, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      4\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# history = model.fit([train_inputs, train_inputs_time, train_inputs, train_inputs, train_inputs], \u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#                     train_labels,\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#                     validation_data=([val_inputs, val_inputs, val_inputs, val_inputs, val_inputs], val_labels),\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#                     epochs=epochs,\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#                     batch_size=batch_size)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit([train_inputs, train_inputs_time, train_inputs, train_inputs, train_inputs], \n\u001b[1;32m     12\u001b[0m                     train_labels, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[19], line 29\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(PS, loss, optimizer, nodes, residual)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Define output layer after U-Net\u001b[39;00m\n\u001b[1;32m     23\u001b[0m temp_out    \u001b[38;5;241m=\u001b[39m Conv3D(filters        \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     24\u001b[0m                      kernel_size    \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     25\u001b[0m                      activation     \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     26\u001b[0m                      padding        \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     27\u001b[0m                      data_format    \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannels_last\u001b[39m\u001b[38;5;124m\"\u001b[39m)(unet)\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranspose_fn\u001b[39m(x):\n\u001b[1;32m     30\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mtranspose(x, perm\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     31\u001b[0m temp_out \u001b[38;5;241m=\u001b[39m Lambda(transpose_fn)(temp_out)\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1395\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1344\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/mcgill/reproducibility/venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/mcgill/reproducibility/venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Train the model\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "model = get_model(PS=batch_size)\n",
    "# history = model.fit([train_inputs, train_inputs_time, train_inputs, train_inputs, train_inputs], \n",
    "#                     train_labels,\n",
    "#                     validation_data=([val_inputs, val_inputs, val_inputs, val_inputs, val_inputs], val_labels),\n",
    "#                     epochs=epochs,\n",
    "#                     batch_size=batch_size)\n",
    "history = model.fit([train_inputs, train_inputs_time, train_inputs, train_inputs, train_inputs], \n",
    "                    train_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14s/step - loss: 4.1026 - mae: 3.6400 - mape: 2013.8885 - mse: 101.5587\n",
      "Epoch 1: val_loss improved from inf to 0.24646, saving model to best_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16s/step - loss: 5.3814 - mae: 4.7666 - mape: 2651.7751 - mse: 135.3835 - val_loss: 0.2465 - val_mae: 0.2404 - val_mape: 95.5294 - val_mse: 0.0702\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14s/step - loss: 0.2590 - mae: 0.2534 - mape: 95.1183 - mse: 0.0816 \n",
      "Epoch 2: val_loss improved from 0.24646 to 0.19857, saving model to best_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 16s/step - loss: 0.2566 - mae: 0.2511 - mape: 95.0123 - mse: 0.0806 - val_loss: 0.1986 - val_mae: 0.1891 - val_mape: 74.9972 - val_mse: 0.0493\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14s/step - loss: 0.2046 - mae: 0.1932 - mape: 74.0067 - mse: 0.0570 \n",
      "Epoch 3: val_loss improved from 0.19857 to 0.17110, saving model to best_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 15s/step - loss: 0.2044 - mae: 0.1923 - mape: 73.7344 - mse: 0.0575 - val_loss: 0.1711 - val_mae: 0.1546 - val_mape: 61.2044 - val_mse: 0.0415\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - loss: 0.1701 - mae: 0.1550 - mape: 60.3166 - mse: 0.0432 \n",
      "Epoch 4: val_loss improved from 0.17110 to 0.14798, saving model to best_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 15s/step - loss: 0.1699 - mae: 0.1553 - mape: 60.0640 - mse: 0.0431 - val_loss: 0.1480 - val_mae: 0.1386 - val_mape: 54.2297 - val_mse: 0.0280\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14s/step - loss: 0.1512 - mae: 0.1405 - mape: 52.2024 - mse: 0.0312 \n",
      "Epoch 5: val_loss did not improve from 0.14798\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 15s/step - loss: 0.1495 - mae: 0.1384 - mape: 51.6579 - mse: 0.0306 - val_loss: 0.1647 - val_mae: 0.1406 - val_mape: 56.7223 - val_mse: 0.0462\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14s/step - loss: 0.1584 - mae: 0.1351 - mape: 53.1194 - mse: 0.0450 \n",
      "Epoch 6: val_loss improved from 0.14798 to 0.12072, saving model to best_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 15s/step - loss: 0.1539 - mae: 0.1312 - mape: 51.5696 - mse: 0.0426 - val_loss: 0.1207 - val_mae: 0.1070 - val_mape: 41.8726 - val_mse: 0.0199\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - loss: 0.1286 - mae: 0.1141 - mape: 42.0748 - mse: 0.0231 \n",
      "Epoch 7: val_loss improved from 0.12072 to 0.10815, saving model to best_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 15s/step - loss: 0.1269 - mae: 0.1125 - mape: 41.9700 - mse: 0.0224 - val_loss: 0.1081 - val_mae: 0.0908 - val_mape: 36.0064 - val_mse: 0.0130\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - loss: 0.1121 - mae: 0.0941 - mape: 37.9777 - mse: 0.0157 \n",
      "Epoch 8: val_loss improved from 0.10815 to 0.09520, saving model to best_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 15s/step - loss: 0.1127 - mae: 0.0944 - mape: 37.9590 - mse: 0.0163 - val_loss: 0.0952 - val_mae: 0.0789 - val_mape: 31.1461 - val_mse: 0.0115\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14s/step - loss: 0.0994 - mae: 0.0830 - mape: 32.7002 - mse: 0.0134 \n",
      "Epoch 9: val_loss did not improve from 0.09520\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 15s/step - loss: 0.0995 - mae: 0.0832 - mape: 32.7926 - mse: 0.0133 - val_loss: 0.0977 - val_mae: 0.0842 - val_mape: 32.3869 - val_mse: 0.0111\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - loss: 0.1017 - mae: 0.0881 - mape: 33.0328 - mse: 0.0125 \n",
      "Epoch 10: val_loss improved from 0.09520 to 0.08929, saving model to best_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 15s/step - loss: 0.1015 - mae: 0.0879 - mape: 33.0690 - mse: 0.0125 - val_loss: 0.0893 - val_mae: 0.0759 - val_mape: 29.1766 - val_mse: 0.0096\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - loss: 0.0931 - mae: 0.0791 - mape: 30.3333 - mse: 0.0117 \n",
      "Epoch 11: val_loss improved from 0.08929 to 0.08772, saving model to best_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 15s/step - loss: 0.0931 - mae: 0.0789 - mape: 30.5183 - mse: 0.0118 - val_loss: 0.0877 - val_mae: 0.0740 - val_mape: 28.9498 - val_mse: 0.0095\n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - loss: 0.0845 - mae: 0.0717 - mape: 31.2258 - mse: 0.0094 \n",
      "Epoch 12: val_loss improved from 0.08772 to 0.08092, saving model to best_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 15s/step - loss: 0.0865 - mae: 0.0735 - mape: 31.0639 - mse: 0.0098 - val_loss: 0.0809 - val_mae: 0.0681 - val_mape: 26.8428 - val_mse: 0.0109\n",
      "Epoch 13/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - loss: 0.0846 - mae: 0.0720 - mape: 27.9567 - mse: 0.0119 \n",
      "Epoch 13: val_loss improved from 0.08092 to 0.07906, saving model to best_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 15s/step - loss: 0.0846 - mae: 0.0721 - mape: 28.0124 - mse: 0.0117 - val_loss: 0.0791 - val_mae: 0.0690 - val_mape: 26.1580 - val_mse: 0.0075\n",
      "Epoch 14/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14s/step - loss: 0.0800 - mae: 0.0700 - mape: 27.1206 - mse: 0.0089 \n",
      "Epoch 14: val_loss did not improve from 0.07906\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 15s/step - loss: 0.0803 - mae: 0.0702 - mape: 27.0277 - mse: 0.0090 - val_loss: 0.1069 - val_mae: 0.0949 - val_mape: 37.4010 - val_mse: 0.0186\n",
      "Epoch 15/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - loss: 0.1074 - mae: 0.0956 - mape: 36.6991 - mse: 0.0206 \n",
      "Epoch 15: val_loss did not improve from 0.07906\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 14s/step - loss: 0.1051 - mae: 0.0935 - mape: 35.8775 - mse: 0.0197 - val_loss: 0.1139 - val_mae: 0.1043 - val_mape: 39.6251 - val_mse: 0.0180\n",
      "Epoch 16/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - loss: 0.1128 - mae: 0.1034 - mape: 38.2468 - mse: 0.0192 \n",
      "Epoch 16: val_loss did not improve from 0.07906\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 14s/step - loss: 0.1127 - mae: 0.1032 - mape: 37.9276 - mse: 0.0192 - val_loss: 0.0807 - val_mae: 0.0698 - val_mape: 27.2383 - val_mse: 0.0087\n",
      "Epoch 17/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - loss: 0.0850 - mae: 0.0733 - mape: 28.7235 - mse: 0.0105 \n",
      "Epoch 17: val_loss did not improve from 0.07906\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 14s/step - loss: 0.0851 - mae: 0.0734 - mape: 28.9602 - mse: 0.0108 - val_loss: 0.0828 - val_mae: 0.0677 - val_mape: 27.5403 - val_mse: 0.0154\n",
      "Epoch 18/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14s/step - loss: 0.0867 - mae: 0.0716 - mape: 29.6425 - mse: 0.0162 \n",
      "Epoch 18: val_loss improved from 0.07906 to 0.07096, saving model to best_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 16s/step - loss: 0.0867 - mae: 0.0717 - mape: 29.5326 - mse: 0.0156 - val_loss: 0.0710 - val_mae: 0.0580 - val_mape: 21.5154 - val_mse: 0.0083\n",
      "Epoch 19/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14s/step - loss: 0.0782 - mae: 0.0646 - mape: 22.4901 - mse: 0.0103 \n",
      "Epoch 19: val_loss improved from 0.07096 to 0.06601, saving model to best_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 15s/step - loss: 0.0767 - mae: 0.0635 - mape: 22.4791 - mse: 0.0099 - val_loss: 0.0660 - val_mae: 0.0565 - val_mape: 20.2925 - val_mse: 0.0053\n",
      "Epoch 20/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 22s/step - loss: 0.0627 - mae: 0.0538 - mape: 20.1805 - mse: 0.0053"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 19\u001b[0m\n\u001b[1;32m      9\u001b[0m checkpoint_callback \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\n\u001b[1;32m     10\u001b[0m     filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.keras\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Filepath where the model will be saved\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,        \u001b[38;5;66;03m# Monitor the validation loss\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m                  \u001b[38;5;66;03m# Verbosity mode\u001b[39;00m\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Train the model with validation and checkpointing\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_inputs_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_inputs_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_inputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     27\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/mcgill/reproducibility/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/mcgill/reproducibility/venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:318\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    317\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 318\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    320\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/Desktop/mcgill/reproducibility/venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/mcgill/reproducibility/venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Desktop/mcgill/reproducibility/venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/mcgill/reproducibility/venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/mcgill/reproducibility/venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Desktop/mcgill/reproducibility/venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Desktop/mcgill/reproducibility/venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/mcgill/reproducibility/venv/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/Desktop/mcgill/reproducibility/venv/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the model\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "model = get_model(PS=batch_size)\n",
    "\n",
    "# Define the checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='best_model.keras',  # Filepath where the model will be saved\n",
    "    monitor='val_loss',        # Monitor the validation loss\n",
    "    save_best_only=True,       # Save only the best model\n",
    "    save_weights_only=False,   # Save the whole model, not just weights\n",
    "    mode='min',                # Mode 'min' means it will save the model with the minimum validation loss\n",
    "    verbose=1                  # Verbosity mode\n",
    ")\n",
    "\n",
    "# Train the model with validation and checkpointing\n",
    "history = model.fit(\n",
    "    [train_inputs, train_inputs_time, train_inputs, train_inputs, train_inputs],\n",
    "    train_labels,\n",
    "    validation_data=([val_inputs, val_inputs_time, val_inputs, val_inputs, val_inputs], val_labels),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = val_inputs[-10:,:,:,:,:]\n",
    "\n",
    "test_inputs_time = val_inputs_time[-10:,:,:,:,:]\n",
    "\n",
    "test_labels = val_labels[-10:,:,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_fn(x):\n",
    "      return tf.transpose(x, perm=[0, 4, 2, 3, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "best_model = load_model('best_model.keras',custom_objects={'grad_loss': grad_loss, \"transpose_fn\": transpose_fn})\n",
    "\n",
    "# Now you can use `best_model` to make predictions or further evaluations\n",
    "predictions = best_model.predict([test_inputs,test_inputs_time,test_inputs,test_inputs,test_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.10565047],\n",
       "        [0.08009063],\n",
       "        [0.06276511],\n",
       "        ...,\n",
       "        [0.05736864],\n",
       "        [0.07549879],\n",
       "        [0.09764508]],\n",
       "\n",
       "       [[0.08541583],\n",
       "        [0.06578466],\n",
       "        [0.04358625],\n",
       "        ...,\n",
       "        [0.04144974],\n",
       "        [0.06119914],\n",
       "        [0.078182  ]],\n",
       "\n",
       "       [[0.07039799],\n",
       "        [0.0516766 ],\n",
       "        [0.0348365 ],\n",
       "        ...,\n",
       "        [0.03283107],\n",
       "        [0.04556884],\n",
       "        [0.0605534 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.08664036],\n",
       "        [0.06774475],\n",
       "        [0.04767932],\n",
       "        ...,\n",
       "        [0.0365563 ],\n",
       "        [0.05740006],\n",
       "        [0.07642516]],\n",
       "\n",
       "       [[0.12355001],\n",
       "        [0.11332931],\n",
       "        [0.08721443],\n",
       "        ...,\n",
       "        [0.05564025],\n",
       "        [0.06870803],\n",
       "        [0.08462681]],\n",
       "\n",
       "       [[0.14623328],\n",
       "        [0.13062647],\n",
       "        [0.09104966],\n",
       "        ...,\n",
       "        [0.06836142],\n",
       "        [0.087678  ],\n",
       "        [0.11300971]]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[0,1,:,:,:] - predictions[0,1,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.20429252],\n",
       "         [0.22046527],\n",
       "         [0.23450242],\n",
       "         ...,\n",
       "         [0.17022377],\n",
       "         [0.14907584],\n",
       "         [0.13062248]],\n",
       "\n",
       "        [[0.20140629],\n",
       "         [0.19970445],\n",
       "         [0.21752869],\n",
       "         ...,\n",
       "         [0.16617085],\n",
       "         [0.14954352],\n",
       "         [0.14288747]],\n",
       "\n",
       "        [[0.2003976 ],\n",
       "         [0.1963866 ],\n",
       "         [0.20930725],\n",
       "         ...,\n",
       "         [0.16388798],\n",
       "         [0.15629013],\n",
       "         [0.1561815 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.16659097],\n",
       "         [0.17072971],\n",
       "         [0.18676652],\n",
       "         ...,\n",
       "         [0.1673332 ],\n",
       "         [0.15889336],\n",
       "         [0.15225995]],\n",
       "\n",
       "        [[0.13582537],\n",
       "         [0.13350594],\n",
       "         [0.15132111],\n",
       "         ...,\n",
       "         [0.15519483],\n",
       "         [0.15459731],\n",
       "         [0.15096231]],\n",
       "\n",
       "        [[0.1228685 ],\n",
       "         [0.12410343],\n",
       "         [0.16084044],\n",
       "         ...,\n",
       "         [0.15190326],\n",
       "         [0.14139992],\n",
       "         [0.121322  ]]],\n",
       "\n",
       "\n",
       "       [[[0.19814698],\n",
       "         [0.22370683],\n",
       "         [0.24103235],\n",
       "         ...,\n",
       "         [0.17047946],\n",
       "         [0.14661355],\n",
       "         [0.12387391]],\n",
       "\n",
       "        [[0.21838163],\n",
       "         [0.23801279],\n",
       "         [0.2602112 ],\n",
       "         ...,\n",
       "         [0.18639836],\n",
       "         [0.1609132 ],\n",
       "         [0.143337  ]],\n",
       "\n",
       "        [[0.23339947],\n",
       "         [0.25212085],\n",
       "         [0.26896095],\n",
       "         ...,\n",
       "         [0.19501702],\n",
       "         [0.1765435 ],\n",
       "         [0.16096559]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.19816977],\n",
       "         [0.21706538],\n",
       "         [0.2371308 ],\n",
       "         ...,\n",
       "         [0.20395003],\n",
       "         [0.18310627],\n",
       "         [0.16408117]],\n",
       "\n",
       "        [[0.16126011],\n",
       "         [0.17148082],\n",
       "         [0.1975957 ],\n",
       "         ...,\n",
       "         [0.18486609],\n",
       "         [0.1717983 ],\n",
       "         [0.15587953]],\n",
       "\n",
       "        [[0.13857685],\n",
       "         [0.15418366],\n",
       "         [0.19376047],\n",
       "         ...,\n",
       "         [0.17214492],\n",
       "         [0.15282834],\n",
       "         [0.12749663]]],\n",
       "\n",
       "\n",
       "       [[[0.33545828],\n",
       "         [0.38224778],\n",
       "         [0.42254776],\n",
       "         ...,\n",
       "         [0.29480687],\n",
       "         [0.24133967],\n",
       "         [0.19501114]],\n",
       "\n",
       "        [[0.34436476],\n",
       "         [0.36615548],\n",
       "         [0.40647274],\n",
       "         ...,\n",
       "         [0.29800153],\n",
       "         [0.25201264],\n",
       "         [0.22072218]],\n",
       "\n",
       "        [[0.3631911 ],\n",
       "         [0.37601003],\n",
       "         [0.4120094 ],\n",
       "         ...,\n",
       "         [0.31009734],\n",
       "         [0.27022782],\n",
       "         [0.24496092]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.2935145 ],\n",
       "         [0.31218433],\n",
       "         [0.34476277],\n",
       "         ...,\n",
       "         [0.29396963],\n",
       "         [0.26413494],\n",
       "         [0.23230416]],\n",
       "\n",
       "        [[0.23829164],\n",
       "         [0.25669235],\n",
       "         [0.2854069 ],\n",
       "         ...,\n",
       "         [0.26712856],\n",
       "         [0.24551757],\n",
       "         [0.21803927]],\n",
       "\n",
       "        [[0.20804895],\n",
       "         [0.22667874],\n",
       "         [0.2831205 ],\n",
       "         ...,\n",
       "         [0.25016102],\n",
       "         [0.21882066],\n",
       "         [0.17356539]]],\n",
       "\n",
       "\n",
       "       [[[0.14531049],\n",
       "         [0.19031557],\n",
       "         [0.21608636],\n",
       "         ...,\n",
       "         [0.14668617],\n",
       "         [0.11708289],\n",
       "         [0.08621054]],\n",
       "\n",
       "        [[0.21195379],\n",
       "         [0.27932546],\n",
       "         [0.3078417 ],\n",
       "         ...,\n",
       "         [0.20236939],\n",
       "         [0.15917134],\n",
       "         [0.11628371]],\n",
       "\n",
       "        [[0.26362625],\n",
       "         [0.33098796],\n",
       "         [0.3566469 ],\n",
       "         ...,\n",
       "         [0.23729253],\n",
       "         [0.19082546],\n",
       "         [0.13790588]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.2311176 ],\n",
       "         [0.2790103 ],\n",
       "         [0.30330348],\n",
       "         ...,\n",
       "         [0.24491689],\n",
       "         [0.19874349],\n",
       "         [0.15163445]],\n",
       "\n",
       "        [[0.19198355],\n",
       "         [0.23410088],\n",
       "         [0.2681738 ],\n",
       "         ...,\n",
       "         [0.21502677],\n",
       "         [0.17185062],\n",
       "         [0.12677659]],\n",
       "\n",
       "        [[0.15312135],\n",
       "         [0.20010868],\n",
       "         [0.23051181],\n",
       "         ...,\n",
       "         [0.18225598],\n",
       "         [0.14525554],\n",
       "         [0.11231941]]],\n",
       "\n",
       "\n",
       "       [[[0.16379334],\n",
       "         [0.1915263 ],\n",
       "         [0.2171986 ],\n",
       "         ...,\n",
       "         [0.16976878],\n",
       "         [0.13957955],\n",
       "         [0.11445046]],\n",
       "\n",
       "        [[0.17101838],\n",
       "         [0.1935764 ],\n",
       "         [0.21199758],\n",
       "         ...,\n",
       "         [0.17297944],\n",
       "         [0.14688694],\n",
       "         [0.12275988]],\n",
       "\n",
       "        [[0.1906679 ],\n",
       "         [0.20516062],\n",
       "         [0.2270005 ],\n",
       "         ...,\n",
       "         [0.18830103],\n",
       "         [0.15471336],\n",
       "         [0.12848465]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.16171148],\n",
       "         [0.17240465],\n",
       "         [0.18414123],\n",
       "         ...,\n",
       "         [0.15888558],\n",
       "         [0.14047606],\n",
       "         [0.1162139 ]],\n",
       "\n",
       "        [[0.14799029],\n",
       "         [0.17088829],\n",
       "         [0.17264003],\n",
       "         ...,\n",
       "         [0.1487765 ],\n",
       "         [0.12693834],\n",
       "         [0.10287921]],\n",
       "\n",
       "        [[0.13608697],\n",
       "         [0.15212049],\n",
       "         [0.15802582],\n",
       "         ...,\n",
       "         [0.13656838],\n",
       "         [0.11844096],\n",
       "         [0.09803273]]]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def uNet(input, time, lat, lon, height, kernel = [5, 3, 3], nodes = [72, 144, 288, 576]):\n",
    "#     '''\n",
    "#     This function defines a U-Net architecture\n",
    "#     :param input: the main-input layer\n",
    "#     :param time: the time input layer\n",
    "#     :param lat, lon, height: additional fields\n",
    "#     :param kernel: Kernel-sizes (default = [5, 3, 3])\n",
    "#     :param nodes: different neuron-sizes if needed (default = [72, 144, 288, 576])\n",
    "#     :return: last layer of constructed model\n",
    "#     '''\n",
    "\n",
    "#     # set Timesteps\n",
    "#     TS = 3\n",
    "#     ##################################################### 1st Block ####################################################\n",
    "#     conv1 = Conv3D(filters      = nodes[0],\n",
    "#                    kernel_size  = (TS, kernel[0], kernel[0]),\n",
    "#                    activation   = 'relu',\n",
    "#                    padding      = 'same',\n",
    "#                    data_format  = 'channels_last')(input)\n",
    "#     mergetime = Concatenate(axis=4)([conv1, lat, lon, height])\n",
    "#     conv1 = Conv3D(filters      = nodes[0],\n",
    "#                    kernel_size  = kernel[0],\n",
    "#                    activation   = 'relu',\n",
    "#                    padding      = 'same',\n",
    "#                    data_format  = 'channels_last')(mergetime)\n",
    "\n",
    "#     pool1 = MaxPooling3D(pool_size = (1, 2, 2))(conv1)\n",
    "\n",
    "#     ##################################################### 2nd Block ####################################################\n",
    "#     conv2 = Conv3D(filters      = nodes[1],\n",
    "#                    kernel_size  = (TS, kernel[1], kernel[1]),\n",
    "#                    activation   = 'relu',\n",
    "#                    padding      = 'same',\n",
    "#                    data_format  = 'channels_last')(pool1)\n",
    "#     conv2 = Conv3D(filters      = nodes[1],\n",
    "#                    kernel_size  = (TS, kernel[1], kernel[1]),\n",
    "#                    activation   = 'relu',\n",
    "#                    padding      = 'same',\n",
    "#                    data_format  = 'channels_last')(conv2)\n",
    "\n",
    "#     pool2 = MaxPooling3D(pool_size = (1, 2, 2))(conv2)\n",
    "\n",
    "#     ##################################################### 3rd Block ####################################################\n",
    "#     conv3 = Conv3D(filters      = nodes[2],\n",
    "#                    kernel_size  = (TS, kernel[2], kernel[2]),\n",
    "#                    activation = 'relu',\n",
    "#                    padding      = 'same',\n",
    "#                    data_format  = 'channels_last')(pool2)\n",
    "#     conv3 = Conv3D(filters      = nodes[2],\n",
    "#                    kernel_size  = (TS, kernel[2], kernel[2]),\n",
    "#                    activation='relu',\n",
    "#                    padding      = 'same',\n",
    "#                    data_format  = 'channels_last')(conv3)\n",
    "\n",
    "#     pool3 = MaxPooling3D(pool_size = (1, 2, 2))(conv3)\n",
    "\n",
    "#     ##################################################### 4th Block ####################################################\n",
    "#     conv4 = Conv3D(filters      = nodes[3],\n",
    "#                    kernel_size  = (TS, kernel[2], kernel[2]),\n",
    "#                    activation='relu',\n",
    "#                    padding      = 'same',\n",
    "#                    data_format  = 'channels_last')(pool3)\n",
    "#     conv4 = Conv3D(filters      = nodes[3],\n",
    "#                    kernel_size  = (TS, kernel[2], kernel[2]),\n",
    "#                    activation='relu',\n",
    "#                    padding      = 'same',\n",
    "#                    data_format  = 'channels_last')(conv4)\n",
    "\n",
    "#     ####################################################### TIME #######################################################\n",
    "#     # Merge time-layer at this point\n",
    "#     mergetime = Concatenate(axis=4)([conv4, time])\n",
    "\n",
    "#     ################################################### UP 3rd Block ###################################################\n",
    "#     # Up-Size again\n",
    "#     up3   = UpSampling3D(size = (1, 2, 2))(mergetime)\n",
    "#     up3   = Conv3D(filters              = nodes[2],\n",
    "#                    kernel_size          = (TS, kernel[1], kernel[1]),\n",
    "#                    activation           = 'relu',\n",
    "#                    padding              = 'same',\n",
    "#                    kernel_initializer   = 'he_normal')(up3)\n",
    "\n",
    "#     # Skip connection\n",
    "#     merge3 = Concatenate(axis=4)([conv3, up3])\n",
    "\n",
    "#     conv3 = Conv3D(filters              = nodes[2],\n",
    "#                    kernel_size          = (TS, kernel[1], kernel[1]),\n",
    "#                    activation           = 'relu',\n",
    "#                    padding              = 'same',\n",
    "#                    data_format          = 'channels_last')(merge3)\n",
    "#     conv3 = Conv3D(filters              = nodes[2],\n",
    "#                    kernel_size          = (TS, kernel[1], kernel[1]),\n",
    "#                    activation           = 'relu',\n",
    "#                    padding              = 'same',\n",
    "#                    data_format          = 'channels_last')(conv3)\n",
    "\n",
    "#     ################################################### UP 2nd Block ###################################################\n",
    "#     up2 = UpSampling3D(size = (1, 2, 2))(conv3)\n",
    "#     up2 = Conv3D(filters                = nodes[1],\n",
    "#                  kernel_size            = (TS, kernel[1], kernel[1]),\n",
    "#                  activation             = 'relu',\n",
    "#                  padding                = 'same',\n",
    "#                  kernel_initializer     = 'he_normal')(up2)\n",
    "\n",
    "#     # Skip connection\n",
    "#     merge2 = Concatenate(axis=4)([conv2, up2])\n",
    "\n",
    "#     conv2 = Conv3D(filters              = nodes[1],\n",
    "#                    kernel_size          = (TS, kernel[1], kernel[1]),\n",
    "#                    activation           = 'relu',\n",
    "#                    padding              = 'same',\n",
    "#                    data_format          = 'channels_last')(merge2)\n",
    "#     conv2 = Conv3D(filters              = nodes[1],\n",
    "#                    kernel_size          = (TS, kernel[1], kernel[1]),\n",
    "#                    activation           = 'relu',\n",
    "#                    padding              = 'same',\n",
    "#                    data_format          = 'channels_last')(conv2)\n",
    "\n",
    "#     ################################################### UP 1st Block ###################################################\n",
    "#     up1 = UpSampling3D(size = (1, 2, 2))(conv2)\n",
    "#     up1 = Conv3D(filters                = nodes[0],\n",
    "#                  kernel_size            = (TS, kernel[0], kernel[0]),\n",
    "#                  activation             = 'relu',\n",
    "#                  padding                = 'same',\n",
    "#                  kernel_initializer     = 'he_normal')(up1)\n",
    "\n",
    "#     merge1 = Concatenate(axis=4)([conv1, up1])\n",
    "\n",
    "#     conv1 = Conv3D(filters              = nodes[0],\n",
    "#                    kernel_size          = (TS, kernel[0], kernel[0]),\n",
    "#                    activation           = 'relu',\n",
    "#                    padding              = 'same',\n",
    "#                    data_format          = 'channels_last')(merge1)\n",
    "#     conv1 = Conv3D(filters              = nodes[0],\n",
    "#                    kernel_size          = (TS, kernel[0], kernel[0]),\n",
    "#                    activation           = 'relu',\n",
    "#                    padding              = 'same',\n",
    "#                    data_format          = 'channels_last')(conv1)\n",
    "\n",
    "#     # last layer is the output\n",
    "#     output = conv1\n",
    "\n",
    "#     return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Input layers\n",
    "# PS = 32\n",
    "# main_input  = Input(shape = (3, PS, PS, 1))\n",
    "# time        = Input(shape = (3, int(PS/8), int(PS/8), 1))\n",
    "# lat         = Input(shape = (3, PS, PS, 1))\n",
    "# lon         = Input(shape = (3, PS, PS, 1)) \n",
    "# height      = Input(shape = (3, PS, PS, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
