{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "# %% \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "#%%\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def grad_loss(v_gt, v):\n",
    "    # Gradient loss\n",
    "    loss = tf.reduce_mean(tf.abs(v - v_gt), axis=[1,2,3])\n",
    "    jy = v[:,:,1:,:,:] - v[:,:,:-1,:,:]\n",
    "    jx = v[:,:,:,1:,:] - v[:,:,:,:-1,:]\n",
    "    jy_ = v_gt[:,:,1:,:,:] - v_gt[:,:,:-1,:,:]\n",
    "    jx_ = v_gt[:,:,:,1:,:] - v_gt[:,:,:,:-1,:]\n",
    "    loss += tf.reduce_mean(tf.abs(jy - jy_), axis=[1,2,3])\n",
    "    loss += tf.reduce_mean(tf.abs(jx - jx_), axis=[1,2,3])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uNet(input, time, lat, lon, height, kernel = [5, 3, 3], nodes = [72, 144, 288, 576]):\n",
    "    '''\n",
    "    This function defines a U-Net architecture\n",
    "    :param input: the main-input layer\n",
    "    :param time: the time input layer\n",
    "    :param lat, lon, height: additional fields\n",
    "    :param kernel: Kernel-sizes (default = [5, 3, 3])\n",
    "    :param nodes: different neuron-sizes if needed (default = [72, 144, 288, 576])\n",
    "    :return: last layer of constructed model\n",
    "    '''\n",
    "\n",
    "    # set Timesteps\n",
    "    TS = 3\n",
    "    ##################################################### 1st Block ####################################################\n",
    "    conv1 = Conv3D(filters      = nodes[0],\n",
    "                   kernel_size  = (TS, kernel[0], kernel[0]),\n",
    "                   activation   = 'relu',\n",
    "                   padding      = 'same',\n",
    "                   data_format  = 'channels_last')(input)\n",
    "    mergetime = Concatenate(axis=4)([conv1, lat, lon, height])\n",
    "    conv1 = Conv3D(filters      = nodes[0],\n",
    "                   kernel_size  = kernel[0],\n",
    "                   activation   = 'relu',\n",
    "                   padding      = 'same',\n",
    "                   data_format  = 'channels_last')(mergetime)\n",
    "\n",
    "    pool1 = MaxPooling3D(pool_size = (1, 2, 2))(conv1)\n",
    "\n",
    "    ##################################################### 2nd Block ####################################################\n",
    "    conv2 = Conv3D(filters      = nodes[1],\n",
    "                   kernel_size  = (TS, kernel[1], kernel[1]),\n",
    "                   activation   = 'relu',\n",
    "                   padding      = 'same',\n",
    "                   data_format  = 'channels_last')(pool1)\n",
    "    conv2 = Conv3D(filters      = nodes[1],\n",
    "                   kernel_size  = (TS, kernel[1], kernel[1]),\n",
    "                   activation   = 'relu',\n",
    "                   padding      = 'same',\n",
    "                   data_format  = 'channels_last')(conv2)\n",
    "\n",
    "    pool2 = MaxPooling3D(pool_size = (1, 2, 2))(conv2)\n",
    "\n",
    "    ##################################################### 3rd Block ####################################################\n",
    "    conv3 = Conv3D(filters      = nodes[2],\n",
    "                   kernel_size  = (TS, kernel[2], kernel[2]),\n",
    "                   activation = 'relu',\n",
    "                   padding      = 'same',\n",
    "                   data_format  = 'channels_last')(pool2)\n",
    "    conv3 = Conv3D(filters      = nodes[2],\n",
    "                   kernel_size  = (TS, kernel[2], kernel[2]),\n",
    "                   activation='relu',\n",
    "                   padding      = 'same',\n",
    "                   data_format  = 'channels_last')(conv3)\n",
    "\n",
    "    pool3 = MaxPooling3D(pool_size = (1, 2, 2))(conv3)\n",
    "\n",
    "    ##################################################### 4th Block ####################################################\n",
    "    conv4 = Conv3D(filters      = nodes[3],\n",
    "                   kernel_size  = (TS, kernel[2], kernel[2]),\n",
    "                   activation='relu',\n",
    "                   padding      = 'same',\n",
    "                   data_format  = 'channels_last')(pool3)\n",
    "    conv4 = Conv3D(filters      = nodes[3],\n",
    "                   kernel_size  = (TS, kernel[2], kernel[2]),\n",
    "                   activation='relu',\n",
    "                   padding      = 'same',\n",
    "                   data_format  = 'channels_last')(conv4)\n",
    "\n",
    "    ####################################################### TIME #######################################################\n",
    "    # Merge time-layer at this point\n",
    "    mergetime = Concatenate(axis=4)([conv4, time])\n",
    "\n",
    "    ################################################### UP 3rd Block ###################################################\n",
    "    # Up-Size again\n",
    "    up3   = UpSampling3D(size = (1, 2, 2))(mergetime)\n",
    "    up3   = Conv3D(filters              = nodes[2],\n",
    "                   kernel_size          = (TS, kernel[1], kernel[1]),\n",
    "                   activation           = 'relu',\n",
    "                   padding              = 'same',\n",
    "                   kernel_initializer   = 'he_normal')(up3)\n",
    "\n",
    "    # Skip connection\n",
    "    merge3 = Concatenate(axis=4)([conv3, up3])\n",
    "\n",
    "    conv3 = Conv3D(filters              = nodes[2],\n",
    "                   kernel_size          = (TS, kernel[1], kernel[1]),\n",
    "                   activation           = 'relu',\n",
    "                   padding              = 'same',\n",
    "                   data_format          = 'channels_last')(merge3)\n",
    "    conv3 = Conv3D(filters              = nodes[2],\n",
    "                   kernel_size          = (TS, kernel[1], kernel[1]),\n",
    "                   activation           = 'relu',\n",
    "                   padding              = 'same',\n",
    "                   data_format          = 'channels_last')(conv3)\n",
    "\n",
    "    ################################################### UP 2nd Block ###################################################\n",
    "    up2 = UpSampling3D(size = (1, 2, 2))(conv3)\n",
    "    up2 = Conv3D(filters                = nodes[1],\n",
    "                 kernel_size            = (TS, kernel[1], kernel[1]),\n",
    "                 activation             = 'relu',\n",
    "                 padding                = 'same',\n",
    "                 kernel_initializer     = 'he_normal')(up2)\n",
    "\n",
    "    # Skip connection\n",
    "    merge2 = Concatenate(axis=4)([conv2, up2])\n",
    "\n",
    "    conv2 = Conv3D(filters              = nodes[1],\n",
    "                   kernel_size          = (TS, kernel[1], kernel[1]),\n",
    "                   activation           = 'relu',\n",
    "                   padding              = 'same',\n",
    "                   data_format          = 'channels_last')(merge2)\n",
    "    conv2 = Conv3D(filters              = nodes[1],\n",
    "                   kernel_size          = (TS, kernel[1], kernel[1]),\n",
    "                   activation           = 'relu',\n",
    "                   padding              = 'same',\n",
    "                   data_format          = 'channels_last')(conv2)\n",
    "\n",
    "    ################################################### UP 1st Block ###################################################\n",
    "    up1 = UpSampling3D(size = (1, 2, 2))(conv2)\n",
    "    up1 = Conv3D(filters                = nodes[0],\n",
    "                 kernel_size            = (TS, kernel[0], kernel[0]),\n",
    "                 activation             = 'relu',\n",
    "                 padding                = 'same',\n",
    "                 kernel_initializer     = 'he_normal')(up1)\n",
    "\n",
    "    merge1 = Concatenate(axis=4)([conv1, up1])\n",
    "\n",
    "    conv1 = Conv3D(filters              = nodes[0],\n",
    "                   kernel_size          = (TS, kernel[0], kernel[0]),\n",
    "                   activation           = 'relu',\n",
    "                   padding              = 'same',\n",
    "                   data_format          = 'channels_last')(merge1)\n",
    "    conv1 = Conv3D(filters              = nodes[0],\n",
    "                   kernel_size          = (TS, kernel[0], kernel[0]),\n",
    "                   activation           = 'relu',\n",
    "                   padding              = 'same',\n",
    "                   data_format          = 'channels_last')(conv1)\n",
    "\n",
    "    # last layer is the output\n",
    "    output = conv1\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(PS=32, loss = grad_loss, optimizer = 'adam', nodes = [72, 144, 288, 576], residual = False):\n",
    "    '''\n",
    "    This function creates the DCN-architecture (residual = False) or RPN-architecture (residual = True).\n",
    "    :param PS: Patch size\n",
    "    :param loss: loss function (default = grad_loss)\n",
    "    :param optimizer: optimizer (default = 'adam')\n",
    "    :param nodes: different neuron-sizes if needed (default = [72, 144, 288, 576])\n",
    "    :param residual: boolean toggeling between RPN (True) and DCN (False)\n",
    "    :return: Model\n",
    "    '''\n",
    "\n",
    "    # Input layers\n",
    "    main_input  = Input(shape = (3, PS, PS, 1))\n",
    "    time        = Input(shape = (3, int(PS/8), int(PS/8), 1))\n",
    "    lat         = Input(shape = (3, PS, PS, 1))\n",
    "    lon         = Input(shape = (3, PS, PS, 1)) \n",
    "    height      = Input(shape = (3, PS, PS, 1))\n",
    "\n",
    "    # Load U-Net\n",
    "    unet        = uNet(main_input, time, lat, lon, height, nodes = nodes)\n",
    "\n",
    "    # Define output layer after U-Net\n",
    "    temp_out    = Conv3D(filters        = 1,\n",
    "                         kernel_size    = (3, 1, 1),\n",
    "                         activation     = 'linear',\n",
    "                         padding        = 'valid',\n",
    "                         data_format    = \"channels_last\")(unet)\n",
    "    \n",
    "    # # Define output layer after U-Net\n",
    "    # temp_out    = Conv3D(filters        = 5,\n",
    "    #                      kernel_size    = (1, 1, 1),\n",
    "    #                      activation     = 'linear',\n",
    "    #                      padding        = 'valid',\n",
    "    #                      data_format    = \"channels_first\")(temp_out)\n",
    "    \n",
    "    # residual layer\n",
    "    if residual:\n",
    "        temp_out = Add()([main_input[:,1,:,:], temp_out])\n",
    "\n",
    "    # create model with the defined Layers\n",
    "    model       = Model(inputs          = [main_input, time, lat, lon, height],\n",
    "                        outputs         = temp_out)\n",
    "\n",
    "    # compile with defined loss and optimizer\n",
    "    model.compile(loss      = loss,\n",
    "                  optimizer = optimizer,\n",
    "                  metrics   = ['mse', 'mae', 'mape'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def main():\n",
    "  model = get_model() # DCN\n",
    "#   model = get_model(residual=True) # RPN\n",
    "  model.summary()\n",
    "  print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want data in the size of patch_size x patch_size in time step of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52704, 23, 34, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "wind_speed_data = np.load('tensor.npy')  # Assuming wind speed is in the first channel\n",
    "print(wind_speed_data.shape)\n",
    "wind_speed_data = wind_speed_data[:, :, :, 0]  # Extract wind speed channel\n",
    "\n",
    "# Normalize the data\n",
    "wind_speed_data = (wind_speed_data - np.min(wind_speed_data)) / (np.max(wind_speed_data) - np.min(wind_speed_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52704, 23, 34)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wind_speed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52702, 3, 32, 32, 1)\n",
      "(52702, 3, 4, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Reshape data to fit the model input shape\n",
    "def reshape_data(data, patch_size=32, time_steps=3):\n",
    "    # Define the target shape\n",
    "    target_shape = (32, 32)\n",
    "    data = data[..., np.newaxis]\n",
    "    # Use tf.image.resize to resize the images\n",
    "    resized_data = tf.image.resize(data, target_shape, method='bilinear')\n",
    "\n",
    "    # Convert back to NumPy array if needed\n",
    "    data = resized_data.numpy()\n",
    "\n",
    "\n",
    "    num_samples = data.shape[0] - time_steps + 1\n",
    "    patches = []\n",
    "    time_patches = []\n",
    "    relative_time = np.zeros((3, 4, 4, 1))\n",
    "\n",
    "    # Assign specific values to each slice along the first axis\n",
    "    relative_time[0, :, :, 0] = -1\n",
    "    relative_time[1, :, :, 0] = 0\n",
    "    relative_time[2, :, :, 0] = 1\n",
    "    for i in range(num_samples):\n",
    "        # print(i, i +time_steps)\n",
    "        patch = data[i:i+time_steps, :, :32]\n",
    "        patches.append(patch)\n",
    "        time_patches.append(relative_time)\n",
    "    patches = np.array(patches)\n",
    "    time_patches = np.array(time_patches)\n",
    "    print(patches.shape)\n",
    "    print(time_patches.shape)\n",
    "    # patches = np.expand_dims(patches, axis=-1)  # Add channel dimension\n",
    "    return patches, time_patches\n",
    "\n",
    "# Example reshape\n",
    "patch_size = 32\n",
    "time_steps = 3\n",
    "wind_speed_patches, time_patches = reshape_data(wind_speed_data, patch_size, time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # Reshape data to fit the model input shape\n",
    "# def reshape_data(data, target_shape=(32, 32)):\n",
    "#     # Reshape data to the target shape\n",
    "#     data = data[..., np.newaxis]\n",
    "#     resized_data = tf.image.resize(data, target_shape, method='bilinear')\n",
    "#     data = resized_data.numpy()\n",
    "#     return data\n",
    "\n",
    "# def create_patches(data, time_steps):\n",
    "#     num_samples = data.shape[0] - time_steps + 1\n",
    "#     patches = []\n",
    "\n",
    "#     relative_time = np.zeros((time_steps, data.shape[1]//8, data.shape[2]//8, 1))\n",
    "#     # relative_time = np.zeros((3, 4, 4, 1))\n",
    "\n",
    "#     # Assign specific values to each slice along the first axis\n",
    "#     # relative_time[0, :, :, 0] = -1\n",
    "#     # relative_time[1, :, :, 0] = 0\n",
    "#     # relative_time[2, :, :, 0] = 1\n",
    "#     for t in range(time_steps):\n",
    "#         relative_time[t, :, :, 0] = t\n",
    "\n",
    "#     for i in range(num_samples):\n",
    "#         patch = data[i:i+time_steps]\n",
    "#         patches.append(patch)\n",
    "\n",
    "#     patches = np.array(patches)\n",
    "#     relative_time_patches = np.tile(relative_time, (num_samples, 1, 1, 1, 1))\n",
    "\n",
    "#     return patches, relative_time_patches\n",
    "\n",
    "\n",
    "# # Parameters\n",
    "# patch_size = 32\n",
    "# time_steps_input = 3\n",
    "# time_steps_label = 5\n",
    "\n",
    "# # Reshape data\n",
    "# reshaped_data = reshape_data(wind_speed_data, target_shape=(32, 32))\n",
    "\n",
    "# # Create training input patches with time_steps_input\n",
    "# input_patches, input_time_patches = create_patches(reshaped_data, time_steps_input)\n",
    "\n",
    "# # Create label patches with time_steps_label\n",
    "# label_patches, label_time_patches = create_patches(reshaped_data, time_steps_label)\n",
    "\n",
    "# input_patches, input_time_patches = input_patches[:label_patches.shape[0],:,:,:,:], input_time_patches[:label_patches.shape[0],:,:,:,:]\n",
    "\n",
    "# print(\"Input patches shape:\", input_patches.shape)\n",
    "# print(\"Input time patches shape:\", input_time_patches.shape)\n",
    "# print(\"Label patches shape:\", label_patches.shape)\n",
    "# print(\"Label time patches shape:\", label_time_patches.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input patches shape: (52700, 3, 32, 32, 1)\n",
      "Input time patches shape: (52700, 3, 4, 4, 1)\n",
      "Label patches shape: (52700, 5, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Reshape data to fit the model input shape\n",
    "def reshape_data(data, target_shape=(32, 32)):\n",
    "    # Reshape data to the target shape\n",
    "    data = data[..., np.newaxis]\n",
    "    resized_data = tf.image.resize(data, target_shape, method='bilinear')\n",
    "    data = resized_data.numpy()\n",
    "    return data\n",
    "\n",
    "def create_patches(data, time_steps):\n",
    "    num_samples = data.shape[0] - time_steps + 1\n",
    "    training_patches = []\n",
    "    patches = []\n",
    "\n",
    "    \n",
    "\n",
    "    for i in range(num_samples):\n",
    "        patch = data[i:i+time_steps]\n",
    "        patches.append(patch)\n",
    "        training_patches.append(patch[::2])\n",
    "    training_timestep = time_steps//2+1\n",
    "    relative_time = np.zeros((time_steps//2+1, data.shape[1]//8, data.shape[2]//8, 1))\n",
    "    # relative_time = np.zeros((3, 4, 4, 1))\n",
    "\n",
    "    # Assign specific values to each slice along the first axis\n",
    "    # relative_time[0, :, :, 0] = -1\n",
    "    # relative_time[1, :, :, 0] = 0\n",
    "    # relative_time[2, :, :, 0] = 1\n",
    "    for t in range(training_timestep):\n",
    "        relative_time[t, :, :, 0] = t\n",
    "    relative_time_patches = np.tile(relative_time, (num_samples, 1, 1, 1, 1))\n",
    "    training_patches = np.array(training_patches)\n",
    "    patches = np.array(patches)\n",
    "\n",
    "    return training_patches, relative_time_patches, patches\n",
    "\n",
    "\n",
    "# Parameters\n",
    "patch_size = 32\n",
    "time_steps_label = 5\n",
    "\n",
    "# Reshape data\n",
    "reshaped_data = reshape_data(wind_speed_data, target_shape=(32, 32))\n",
    "\n",
    "# Create label patches with time_steps_label\n",
    "input_patches, input_time_patches, label_patches = create_patches(reshaped_data, time_steps_label)\n",
    "\n",
    "# input_patches, input_time_patches = input_patches[:label_patches.shape[0],:,:,:,:], input_time_patches[:label_patches.shape[0],:,:,:,:]\n",
    "\n",
    "print(\"Input patches shape:\", input_patches.shape)\n",
    "print(\"Input time patches shape:\", input_time_patches.shape)\n",
    "print(\"Label patches shape:\", label_patches.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split data\n",
    "# train_inputs, val_inputs, train_inputs_time, val_inputs_time = train_test_split(\n",
    "#     input_patches, input_time_patches, test_size=0.2, random_state=42)\n",
    "\n",
    "# train_labels, val_labels, train_labels_time, val_labels_time = train_test_split(\n",
    "#     label_patches, test_size=0.2, random_state=42)\n",
    "# print(\"Training input patches shape:\", train_inputs.shape)\n",
    "# print(\"Training input time patches shape:\", train_inputs_time.shape)\n",
    "# print(\"Val input time patches shape:\", val_inputs_time.shape)\n",
    "# print(\"Validation input patches shape:\", val_inputs.shape)\n",
    "# print(\"Training label patches shape:\", train_labels.shape)\n",
    "# print(\"Validation label patches shape:\", val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the size of the training set\n",
    "train_size = int(0.8 * len(input_patches))  # 80% for training\n",
    "\n",
    "# Create indices\n",
    "indices = np.arange(len(input_patches))\n",
    "np.random.seed(42)  # Set seed for reproducibility\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Split indices into training and validation\n",
    "train_indices = indices[:train_size]\n",
    "val_indices = indices[train_size:]\n",
    "\n",
    "# Use the indices to split the data\n",
    "train_inputs = input_patches[train_indices]\n",
    "val_inputs = input_patches[val_indices]\n",
    "\n",
    "train_inputs_time = input_time_patches[train_indices]\n",
    "val_inputs_time = input_time_patches[val_indices]\n",
    "\n",
    "train_labels = label_patches[train_indices]\n",
    "val_labels = label_patches[val_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42160, 5, 32, 32, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%\n",
    "# # Train the model\n",
    "# epochs = 5\n",
    "# batch_size = 32\n",
    "# model = get_model(PS=batch_size)\n",
    "# # history = model.fit([train_inputs, train_inputs_time, train_inputs, train_inputs, train_inputs], \n",
    "# #                     train_labels,\n",
    "# #                     validation_data=([val_inputs, val_inputs, val_inputs, val_inputs, val_inputs], val_labels),\n",
    "# #                     epochs=epochs,\n",
    "# #                     batch_size=batch_size)\n",
    "# history = model.fit([train_inputs, train_inputs_time, train_inputs, train_inputs, train_inputs], \n",
    "#                     train_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1318/1318\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18s/step - loss: 0.1722 - mae: 0.1516 - mape: 69.6839 - mse: 4.1816 "
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 1 of layer \"functional\" is incompatible with the layer: expected shape=(None, 3, 4, 4, 1), found shape=(None, 3, 32, 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 19\u001b[0m\n\u001b[1;32m      9\u001b[0m checkpoint_callback \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\n\u001b[1;32m     10\u001b[0m     filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.keras\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Filepath where the model will be saved\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,        \u001b[38;5;66;03m# Monitor the validation loss\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m                  \u001b[38;5;66;03m# Verbosity mode\u001b[39;00m\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Train the model with validation and checkpointing\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_inputs_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_inputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     27\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/mcgill/reproducibility/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Desktop/mcgill/reproducibility/venv/lib/python3.11/site-packages/keras/src/layers/input_spec.py:245\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[0;32m--> 245\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    246\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    249\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Input 1 of layer \"functional\" is incompatible with the layer: expected shape=(None, 3, 4, 4, 1), found shape=(None, 3, 32, 32)"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the model\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "model = get_model(PS=batch_size)\n",
    "\n",
    "# Define the checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='best_model.keras',  # Filepath where the model will be saved\n",
    "    monitor='val_loss',        # Monitor the validation loss\n",
    "    save_best_only=True,       # Save only the best model\n",
    "    save_weights_only=False,   # Save the whole model, not just weights\n",
    "    mode='min',                # Mode 'min' means it will save the model with the minimum validation loss\n",
    "    verbose=1                  # Verbosity mode\n",
    ")\n",
    "\n",
    "# Train the model with validation and checkpointing\n",
    "history = model.fit(\n",
    "    [train_inputs, train_inputs_time, train_inputs, train_inputs, train_inputs],\n",
    "    train_labels,\n",
    "    validation_data=([val_inputs, val_inputs, val_inputs, val_inputs, val_inputs], val_labels),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def uNet(input, time, lat, lon, height, kernel = [5, 3, 3], nodes = [72, 144, 288, 576]):\n",
    "#     '''\n",
    "#     This function defines a U-Net architecture\n",
    "#     :param input: the main-input layer\n",
    "#     :param time: the time input layer\n",
    "#     :param lat, lon, height: additional fields\n",
    "#     :param kernel: Kernel-sizes (default = [5, 3, 3])\n",
    "#     :param nodes: different neuron-sizes if needed (default = [72, 144, 288, 576])\n",
    "#     :return: last layer of constructed model\n",
    "#     '''\n",
    "\n",
    "#     # set Timesteps\n",
    "#     TS = 3\n",
    "#     ##################################################### 1st Block ####################################################\n",
    "#     conv1 = Conv3D(filters      = nodes[0],\n",
    "#                    kernel_size  = (TS, kernel[0], kernel[0]),\n",
    "#                    activation   = 'relu',\n",
    "#                    padding      = 'same',\n",
    "#                    data_format  = 'channels_last')(input)\n",
    "#     mergetime = Concatenate(axis=4)([conv1, lat, lon, height])\n",
    "#     conv1 = Conv3D(filters      = nodes[0],\n",
    "#                    kernel_size  = kernel[0],\n",
    "#                    activation   = 'relu',\n",
    "#                    padding      = 'same',\n",
    "#                    data_format  = 'channels_last')(mergetime)\n",
    "\n",
    "#     pool1 = MaxPooling3D(pool_size = (1, 2, 2))(conv1)\n",
    "\n",
    "#     ##################################################### 2nd Block ####################################################\n",
    "#     conv2 = Conv3D(filters      = nodes[1],\n",
    "#                    kernel_size  = (TS, kernel[1], kernel[1]),\n",
    "#                    activation   = 'relu',\n",
    "#                    padding      = 'same',\n",
    "#                    data_format  = 'channels_last')(pool1)\n",
    "#     conv2 = Conv3D(filters      = nodes[1],\n",
    "#                    kernel_size  = (TS, kernel[1], kernel[1]),\n",
    "#                    activation   = 'relu',\n",
    "#                    padding      = 'same',\n",
    "#                    data_format  = 'channels_last')(conv2)\n",
    "\n",
    "#     pool2 = MaxPooling3D(pool_size = (1, 2, 2))(conv2)\n",
    "\n",
    "#     ##################################################### 3rd Block ####################################################\n",
    "#     conv3 = Conv3D(filters      = nodes[2],\n",
    "#                    kernel_size  = (TS, kernel[2], kernel[2]),\n",
    "#                    activation = 'relu',\n",
    "#                    padding      = 'same',\n",
    "#                    data_format  = 'channels_last')(pool2)\n",
    "#     conv3 = Conv3D(filters      = nodes[2],\n",
    "#                    kernel_size  = (TS, kernel[2], kernel[2]),\n",
    "#                    activation='relu',\n",
    "#                    padding      = 'same',\n",
    "#                    data_format  = 'channels_last')(conv3)\n",
    "\n",
    "#     pool3 = MaxPooling3D(pool_size = (1, 2, 2))(conv3)\n",
    "\n",
    "#     ##################################################### 4th Block ####################################################\n",
    "#     conv4 = Conv3D(filters      = nodes[3],\n",
    "#                    kernel_size  = (TS, kernel[2], kernel[2]),\n",
    "#                    activation='relu',\n",
    "#                    padding      = 'same',\n",
    "#                    data_format  = 'channels_last')(pool3)\n",
    "#     conv4 = Conv3D(filters      = nodes[3],\n",
    "#                    kernel_size  = (TS, kernel[2], kernel[2]),\n",
    "#                    activation='relu',\n",
    "#                    padding      = 'same',\n",
    "#                    data_format  = 'channels_last')(conv4)\n",
    "\n",
    "#     ####################################################### TIME #######################################################\n",
    "#     # Merge time-layer at this point\n",
    "#     mergetime = Concatenate(axis=4)([conv4, time])\n",
    "\n",
    "#     ################################################### UP 3rd Block ###################################################\n",
    "#     # Up-Size again\n",
    "#     up3   = UpSampling3D(size = (1, 2, 2))(mergetime)\n",
    "#     up3   = Conv3D(filters              = nodes[2],\n",
    "#                    kernel_size          = (TS, kernel[1], kernel[1]),\n",
    "#                    activation           = 'relu',\n",
    "#                    padding              = 'same',\n",
    "#                    kernel_initializer   = 'he_normal')(up3)\n",
    "\n",
    "#     # Skip connection\n",
    "#     merge3 = Concatenate(axis=4)([conv3, up3])\n",
    "\n",
    "#     conv3 = Conv3D(filters              = nodes[2],\n",
    "#                    kernel_size          = (TS, kernel[1], kernel[1]),\n",
    "#                    activation           = 'relu',\n",
    "#                    padding              = 'same',\n",
    "#                    data_format          = 'channels_last')(merge3)\n",
    "#     conv3 = Conv3D(filters              = nodes[2],\n",
    "#                    kernel_size          = (TS, kernel[1], kernel[1]),\n",
    "#                    activation           = 'relu',\n",
    "#                    padding              = 'same',\n",
    "#                    data_format          = 'channels_last')(conv3)\n",
    "\n",
    "#     ################################################### UP 2nd Block ###################################################\n",
    "#     up2 = UpSampling3D(size = (1, 2, 2))(conv3)\n",
    "#     up2 = Conv3D(filters                = nodes[1],\n",
    "#                  kernel_size            = (TS, kernel[1], kernel[1]),\n",
    "#                  activation             = 'relu',\n",
    "#                  padding                = 'same',\n",
    "#                  kernel_initializer     = 'he_normal')(up2)\n",
    "\n",
    "#     # Skip connection\n",
    "#     merge2 = Concatenate(axis=4)([conv2, up2])\n",
    "\n",
    "#     conv2 = Conv3D(filters              = nodes[1],\n",
    "#                    kernel_size          = (TS, kernel[1], kernel[1]),\n",
    "#                    activation           = 'relu',\n",
    "#                    padding              = 'same',\n",
    "#                    data_format          = 'channels_last')(merge2)\n",
    "#     conv2 = Conv3D(filters              = nodes[1],\n",
    "#                    kernel_size          = (TS, kernel[1], kernel[1]),\n",
    "#                    activation           = 'relu',\n",
    "#                    padding              = 'same',\n",
    "#                    data_format          = 'channels_last')(conv2)\n",
    "\n",
    "#     ################################################### UP 1st Block ###################################################\n",
    "#     up1 = UpSampling3D(size = (1, 2, 2))(conv2)\n",
    "#     up1 = Conv3D(filters                = nodes[0],\n",
    "#                  kernel_size            = (TS, kernel[0], kernel[0]),\n",
    "#                  activation             = 'relu',\n",
    "#                  padding                = 'same',\n",
    "#                  kernel_initializer     = 'he_normal')(up1)\n",
    "\n",
    "#     merge1 = Concatenate(axis=4)([conv1, up1])\n",
    "\n",
    "#     conv1 = Conv3D(filters              = nodes[0],\n",
    "#                    kernel_size          = (TS, kernel[0], kernel[0]),\n",
    "#                    activation           = 'relu',\n",
    "#                    padding              = 'same',\n",
    "#                    data_format          = 'channels_last')(merge1)\n",
    "#     conv1 = Conv3D(filters              = nodes[0],\n",
    "#                    kernel_size          = (TS, kernel[0], kernel[0]),\n",
    "#                    activation           = 'relu',\n",
    "#                    padding              = 'same',\n",
    "#                    data_format          = 'channels_last')(conv1)\n",
    "\n",
    "#     # last layer is the output\n",
    "#     output = conv1\n",
    "\n",
    "#     return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Input layers\n",
    "# PS = 32\n",
    "# main_input  = Input(shape = (3, PS, PS, 1))\n",
    "# time        = Input(shape = (3, int(PS/8), int(PS/8), 1))\n",
    "# lat         = Input(shape = (3, PS, PS, 1))\n",
    "# lon         = Input(shape = (3, PS, PS, 1)) \n",
    "# height      = Input(shape = (3, PS, PS, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
